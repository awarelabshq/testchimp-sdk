{
  "name": "llm-eval-js",
  "version": "0.1.0",
  "description": "A library for evaluating LLM outputs in js based test frameworks (Playwright etc.)",
  "main": "index.js",
  "scripts": {
    "test": "echo \"No tests yet\" && exit 0"
  },
  "keywords": [
    "Playwright",
    "Cypress",
    "AI evaluation",
    "test automation"
  ],
  "author": "Aware Labs",
  "license": "GPL-3.0-only",
  "dependencies": {
    "openai": "^4.85.4"
  }
}
